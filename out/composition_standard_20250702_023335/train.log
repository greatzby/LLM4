[2025-07-02 02:33:35,356][INFO] ============================================================
[2025-07-02 02:33:35,357][INFO] Configuration: {'experiment_name': 'composition', 'total_nodes': 90, 'n_layer': 1, 'n_head': 1, 'n_embd': 120, 'max_iters': 200000, 'test_interval': 1000, 'device': 'cuda:0', 'learning_rate': 0.0005, 'batch_size': 1024, 'train_paths_per_pair': 10, 'checkpoint_interval': 5000, 'seed': 42, 'training_mode': 'standard', 'mixed_ratio': 0.1, 'temperature': 0.8, 'top_k': 50}
[2025-07-02 02:33:35,357][INFO] ============================================================
[2025-07-02 02:33:37,715][INFO] Iter 0: loss=0.0000, TF: S1->S3=0.00%, AR: S1->S3=0.00%
[2025-07-02 02:34:03,522][INFO] Iter 1000: loss=2.1080, TF: S1->S3=60.85%, AR: S1->S3=0.00%
[2025-07-02 02:34:29,330][INFO] Iter 2000: loss=0.6813, TF: S1->S3=61.84%, AR: S1->S3=0.00%
[2025-07-02 02:34:55,171][INFO] Iter 3000: loss=0.6717, TF: S1->S3=61.55%, AR: S1->S3=0.00%
[2025-07-02 02:35:20,989][INFO] Iter 4000: loss=0.6700, TF: S1->S3=60.75%, AR: S1->S3=0.00%
[2025-07-02 02:35:46,854][INFO] Iter 5000: loss=0.6689, TF: S1->S3=61.65%, AR: S1->S3=0.00%
[2025-07-02 02:36:12,703][INFO] Iter 6000: loss=0.6688, TF: S1->S3=59.76%, AR: S1->S3=0.00%
[2025-07-02 02:36:38,501][INFO] Iter 7000: loss=0.6681, TF: S1->S3=60.36%, AR: S1->S3=0.00%
[2025-07-02 02:37:04,301][INFO] Iter 8000: loss=0.6680, TF: S1->S3=61.15%, AR: S1->S3=0.00%
[2025-07-02 02:37:30,217][INFO] Iter 9000: loss=0.6677, TF: S1->S3=61.05%, AR: S1->S3=0.00%
[2025-07-02 02:37:56,162][INFO] Iter 10000: loss=0.6677, TF: S1->S3=60.75%, AR: S1->S3=0.00%
[2025-07-02 02:38:22,028][INFO] Iter 11000: loss=0.6674, TF: S1->S3=59.76%, AR: S1->S3=0.00%
[2025-07-02 02:38:47,941][INFO] Iter 12000: loss=0.6674, TF: S1->S3=59.27%, AR: S1->S3=0.00%
[2025-07-02 02:39:13,954][INFO] Iter 13000: loss=0.6674, TF: S1->S3=57.98%, AR: S1->S3=0.00%
[2025-07-02 02:39:39,975][INFO] Iter 14000: loss=0.6671, TF: S1->S3=59.17%, AR: S1->S3=0.00%
[2025-07-02 02:40:05,937][INFO] Iter 15000: loss=0.6671, TF: S1->S3=60.36%, AR: S1->S3=0.00%
[2025-07-02 02:40:31,975][INFO] Iter 16000: loss=0.6672, TF: S1->S3=59.17%, AR: S1->S3=0.00%
[2025-07-02 02:40:57,967][INFO] Iter 17000: loss=0.6671, TF: S1->S3=60.36%, AR: S1->S3=0.00%
[2025-07-02 02:41:23,953][INFO] Iter 18000: loss=0.6669, TF: S1->S3=55.10%, AR: S1->S3=0.00%
[2025-07-02 02:41:49,924][INFO] Iter 19000: loss=0.6668, TF: S1->S3=55.50%, AR: S1->S3=0.00%
[2025-07-02 02:42:15,936][INFO] Iter 20000: loss=0.6668, TF: S1->S3=57.98%, AR: S1->S3=0.00%
[2025-07-02 02:42:41,984][INFO] Iter 21000: loss=0.6669, TF: S1->S3=53.91%, AR: S1->S3=0.00%
[2025-07-02 02:43:07,895][INFO] Iter 22000: loss=0.6669, TF: S1->S3=54.51%, AR: S1->S3=0.00%
[2025-07-02 02:43:33,928][INFO] Iter 23000: loss=0.6670, TF: S1->S3=59.46%, AR: S1->S3=0.00%
[2025-07-02 02:43:59,942][INFO] Iter 24000: loss=0.6670, TF: S1->S3=57.38%, AR: S1->S3=0.00%
[2025-07-02 02:44:25,899][INFO] Iter 25000: loss=0.6667, TF: S1->S3=55.10%, AR: S1->S3=0.00%
[2025-07-02 02:44:51,945][INFO] Iter 26000: loss=0.6667, TF: S1->S3=48.46%, AR: S1->S3=0.00%
[2025-07-02 02:45:17,994][INFO] Iter 27000: loss=0.6670, TF: S1->S3=54.81%, AR: S1->S3=0.00%
[2025-07-02 02:45:44,019][INFO] Iter 28000: loss=0.6669, TF: S1->S3=53.02%, AR: S1->S3=0.00%
[2025-07-02 02:46:09,970][INFO] Iter 29000: loss=0.6668, TF: S1->S3=49.45%, AR: S1->S3=0.00%
[2025-07-02 02:46:35,996][INFO] Iter 30000: loss=0.6669, TF: S1->S3=56.10%, AR: S1->S3=0.00%
[2025-07-02 02:47:02,043][INFO] Iter 31000: loss=0.6665, TF: S1->S3=54.81%, AR: S1->S3=0.00%
[2025-07-02 02:47:28,031][INFO] Iter 32000: loss=0.6666, TF: S1->S3=53.02%, AR: S1->S3=0.00%
[2025-07-02 02:47:54,029][INFO] Iter 33000: loss=0.6668, TF: S1->S3=55.50%, AR: S1->S3=0.00%
[2025-07-02 02:48:20,058][INFO] Iter 34000: loss=0.6668, TF: S1->S3=50.55%, AR: S1->S3=0.00%
[2025-07-02 02:48:46,039][INFO] Iter 35000: loss=0.6667, TF: S1->S3=56.19%, AR: S1->S3=0.00%
[2025-07-02 02:49:12,061][INFO] Iter 36000: loss=0.6668, TF: S1->S3=54.11%, AR: S1->S3=0.00%
