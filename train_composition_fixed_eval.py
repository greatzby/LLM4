# train_composition_fixed_eval.py
import os
import time
import math
import pickle
import argparse
import numpy as np
import torch
import torch.nn.functional as F
import networkx as nx
from contextlib import nullcontext
import matplotlib.pyplot as plt
from datetime import datetime
from collections import defaultdict

from model import GPTConfig, GPT
from logger import get_logger

def parse_args():
    parser = argparse.ArgumentParser(description='Composition Ability Training')
    parser.add_argument('--data_dir', type=str, default='data/simple_graph/composition_90_fixed')
    parser.add_argument('--n_layer', type=int, default=1)
    parser.add_argument('--n_head', type=int, default=1)
    parser.add_argument('--n_embd', type=int, default=120)
    parser.add_argument('--max_iters', type=int, default=50000)
    parser.add_argument('--test_interval', type=int, default=1000)
    parser.add_argument('--device', type=str, default='cuda:0')
    parser.add_argument('--learning_rate', type=float, default=5e-4)
    parser.add_argument('--batch_size', type=int, default=1024)
    parser.add_argument('--train_paths_per_pair', type=int, default=10)
    parser.add_argument('--checkpoint_interval', type=int, default=5000)
    parser.add_argument('--seed', type=int, default=42)
    parser.add_argument('--eval_temperature', type=float, default=0.1)
    parser.add_argument('--eval_top_k', type=int, default=10)
    return parser.parse_args()

def set_seed(seed):
    import random
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

@torch.no_grad()
def evaluate_ar_correct(model, test_file, stages, stoi, itos, device, G, temperature=0.1, top_k=10, max_eval_per_type=50):
    """ä¿®å¤åçš„ARè¯„ä¼°å‡½æ•°ï¼ˆæ­£ç¡®å¤„ç†å­—ç¬¦ç¼–ç ï¼‰"""
    model.eval()
    
    S1, S2, S3 = stages
    
    # è¯»å–æµ‹è¯•æ•°æ®
    with open(test_file, 'r') as f:
        test_lines = [line.strip() for line in f.readlines() if line.strip()]
    
    # åˆ†ç±»æµ‹è¯•æ•°æ®
    test_by_type = {
        'S1->S2': [],
        'S2->S3': [],
        'S1->S3': []
    }
    
    for line in test_lines:
        parts = line.split()
        if len(parts) >= 2:
            try:
                source, target = int(parts[0]), int(parts[1])
                if source in S1 and target in S2:
                    test_by_type['S1->S2'].append((source, target, parts))
                elif source in S2 and target in S3:
                    test_by_type['S2->S3'].append((source, target, parts))
                elif source in S1 and target in S3:
                    test_by_type['S1->S3'].append((source, target, parts))
            except:
                continue
    
    # ç»“æœç»Ÿè®¡
    results = {}
    
    for path_type, test_cases in test_by_type.items():
        n_eval = min(len(test_cases), max_eval_per_type)
        results[path_type] = {
            'correct': 0,
            'total': n_eval,
            'errors': defaultdict(int),
            'examples': {'success': [], 'failure': []}
        }
        
        # è¯„ä¼°
        for idx in range(n_eval):
            source, target, true_path_parts = test_cases[idx]
            
            # æ„å»ºpromptå­—ç¬¦ä¸²ï¼šsource target source
            prompt_str = f"{source} {target} {source}"
            
            # æŒ‰å­—ç¬¦ç¼–ç 
            prompt_ids = []
            for char in prompt_str:
                if char in stoi:
                    prompt_ids.append(stoi[char])
                else:
                    prompt_ids.append(0)  # PAD for unknown chars
            
            if len(prompt_ids) == 0:
                results[path_type]['errors']['encoding_error'] += 1
                continue
            
            x = torch.tensor(prompt_ids, dtype=torch.long, device=device).unsqueeze(0)
            
            # ç”Ÿæˆ
            with torch.no_grad():
                y = model.generate(x, max_new_tokens=30, temperature=temperature, top_k=top_k)
            
            # è§£ç è·¯å¾„
            generated_ids = y[0].tolist()[len(prompt_ids):]  # è·³è¿‡promptéƒ¨åˆ†
            
            # å°†token idsè½¬æ¢å›å­—ç¬¦
            generated_chars = []
            for token_id in generated_ids:
                if token_id == 1:  # newline
                    break
                if token_id in itos and token_id > 1:  # è·³è¿‡PADå’Œnewline
                    generated_chars.append(itos[token_id])
            
            # å°†å­—ç¬¦åºåˆ—è§£æä¸ºæ•°å­—åˆ—è¡¨
            generated_str = ''.join(generated_chars)
            generated = []
            current_num = ""
            
            for char in generated_str:
                if char == ' ':
                    if current_num and current_num.isdigit():
                        generated.append(int(current_num))
                    current_num = ""
                elif char.isdigit():
                    current_num += char
                else:
                    # éæ•°å­—éç©ºæ ¼å­—ç¬¦ï¼Œé‡ç½®
                    if current_num and current_num.isdigit():
                        generated.append(int(current_num))
                    current_num = ""
            
            # å¤„ç†æœ€åä¸€ä¸ªæ•°å­—
            if current_num and current_num.isdigit():
                generated.append(int(current_num))
            
            # éªŒè¯ç»“æœ
            success = False
            error_type = None
            
            if len(generated) >= 2:
                if generated[0] == source and generated[-1] == target:
                    if path_type == 'S1->S3':
                        # å¯¹äºS1->S3ï¼Œæ£€æŸ¥æ˜¯å¦ç»è¿‡S2
                        has_s2 = any(node in S2 for node in generated[1:-1])
                        if has_s2:
                            success = True
                        else:
                            error_type = 'no_s2_intermediate'
                    else:
                        # å¯¹äºS1->S2å’ŒS2->S3ï¼ŒéªŒè¯è·¯å¾„æœ‰æ•ˆæ€§
                        success = True
                        for i in range(len(generated) - 1):
                            if not G.has_edge(str(generated[i]), str(generated[i+1])):
                                success = False
                                error_type = 'invalid_edge'
                                break
                else:
                    error_type = 'wrong_endpoints'
            else:
                error_type = 'too_short'
            
            if success:
                results[path_type]['correct'] += 1
                if len(results[path_type]['examples']['success']) < 3:
                    results[path_type]['examples']['success'].append({
                        'source': source,
                        'target': target, 
                        'generated': generated,
                        'prompt': prompt_str,
                        'true': [int(x) for x in true_path_parts if x.isdigit()]
                    })
            else:
                results[path_type]['errors'][error_type if error_type else 'unknown'] += 1
                if len(results[path_type]['examples']['failure']) < 3:
                    results[path_type]['examples']['failure'].append({
                        'source': source,
                        'target': target,
                        'generated': generated,
                        'error': error_type,
                        'prompt': prompt_str
                    })
        
        # è®¡ç®—å‡†ç¡®ç‡
        results[path_type]['accuracy'] = results[path_type]['correct'] / results[path_type]['total'] if results[path_type]['total'] > 0 else 0.0
    
    model.train()
    return results

def main():
    args = parse_args()
    set_seed(args.seed)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    out_dir = f'out/composition_fixed_{timestamp}'
    os.makedirs(out_dir, exist_ok=True)
    
    # è®¾ç½®logger
    logger = get_logger(os.path.join(out_dir, "train.log"))
    
    print("="*60)
    print(f"Composition Ability Training (Fixed Evaluation)")
    print(f"Model: {args.n_layer}L-{args.n_head}H-{args.n_embd}D")
    print(f"Data: {args.data_dir}")
    print("="*60)
    
    # è®°å½•é…ç½®
    logger.info("="*60)
    logger.info(f"Configuration: {vars(args)}")
    logger.info("="*60)
    
    # åŠ è½½æ•°æ®
    data_dir = args.data_dir
    
    # åŠ è½½é˜¶æ®µä¿¡æ¯
    with open(os.path.join(data_dir, 'stage_info.pkl'), 'rb') as f:
        stage_info = pickle.load(f)
    stages = stage_info['stages']
    S1, S2, S3 = stages
    
    print(f"Stage info: S1={len(S1)} nodes, S2={len(S2)} nodes, S3={len(S3)} nodes")
    
    # åŠ è½½å…ƒä¿¡æ¯
    with open(os.path.join(data_dir, 'meta.pkl'), 'rb') as f:
        meta = pickle.load(f)
    
    stoi, itos = meta['stoi'], meta['itos']
    block_size = meta['block_size']
    vocab_size = meta['vocab_size']
    
    print(f"Vocabulary size: {vocab_size}")
    print(f"Block size: {block_size}")
    print(f"Character vocabulary: {[c for c in stoi.keys() if c not in ['[PAD]', '\\n']]}")
    
    # åŠ è½½å›¾
    G = nx.read_graphml(os.path.join(data_dir, 'composition_graph.graphml'))
    print(f"Graph loaded: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges")
    
    # åŠ è½½æ•°æ®
    train_data = np.memmap(os.path.join(data_dir, f'train_{args.train_paths_per_pair}.bin'), 
                          dtype=np.uint16, mode='r')
    val_data = np.memmap(os.path.join(data_dir, 'val.bin'), dtype=np.uint16, mode='r')
    test_file = os.path.join(data_dir, 'test.txt')
    
    print(f"Data loaded: train={len(train_data)//(block_size+1)} sequences, val={len(val_data)//(block_size+1)} sequences")
    
    # åˆå§‹åŒ–æ¨¡å‹
    model_args = dict(
        n_layer=args.n_layer,
        n_head=args.n_head,
        n_embd=args.n_embd,
        block_size=block_size,
        bias=False,
        vocab_size=vocab_size,
        dropout=0.0
    )
    
    gptconf = GPTConfig(**model_args)
    model = GPT(gptconf).to(args.device)
    
    print(f"Model initialized: {sum(p.numel() for p in model.parameters())/1e6:.2f}M parameters")
    
    # ä¼˜åŒ–å™¨
    optimizer = model.configure_optimizers(
        weight_decay=1e-1,
        learning_rate=args.learning_rate,
        betas=(0.9, 0.95),
        device_type='cuda' if 'cuda' in args.device else 'cpu'
    )
    
    # æ•°æ®åŠ è½½å‡½æ•°
    def get_batch(split):
        data = train_data if split == 'train' else val_data
        data_size = block_size + 1
        
        # ç¡®ä¿å¯¹é½åˆ°åºåˆ—è¾¹ç•Œ
        num_sequences = len(data) // data_size
        seq_indices = torch.randint(0, num_sequences, (args.batch_size,))
        ix = seq_indices * data_size
        
        x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])
        y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])
        
        return x.to(args.device), y.to(args.device)
    
    # è®­ç»ƒå†å²
    history = {
        'iter': [],
        'train_loss': [],
        'val_loss': [],
        'ar_s1_s2': [],
        'ar_s2_s3': [],
        'ar_s1_s3': [],
        's1_s3_errors': []
    }
    
    # è®­ç»ƒå¾ªç¯
    print("\nStarting training...")
    running_loss = 0
    loss_count = 0
    
    for iter_num in range(args.max_iters + 1):
        # å­¦ä¹ ç‡è°ƒåº¦
        lr = args.learning_rate
        if iter_num < 2000:
            lr = args.learning_rate * iter_num / 2000
        elif iter_num > args.max_iters * 0.9:
            lr = args.learning_rate * 0.1
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr
        
        # å®šæœŸè¯„ä¼°
        if iter_num % args.test_interval == 0:
            # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤±
            avg_train_loss = running_loss / loss_count if loss_count > 0 else 0
            
            # éªŒè¯é›†æŸå¤±
            model.eval()
            val_losses = []
            for _ in range(10):
                X_val, Y_val = get_batch('val')
                with torch.no_grad():
                    _, loss = model(X_val, Y_val)
                val_losses.append(loss.item())
            val_loss = np.mean(val_losses)
            
            # ARè¯„ä¼°ï¼ˆä½¿ç”¨ä¿®å¤çš„å‡½æ•°ï¼‰
            ar_results = evaluate_ar_correct(model, test_file, stages, stoi, itos, args.device, G,
                                           temperature=args.eval_temperature, top_k=args.eval_top_k)
            
            # è®°å½•å†å²
            history['iter'].append(iter_num)
            history['train_loss'].append(avg_train_loss)
            history['val_loss'].append(val_loss)
            history['ar_s1_s2'].append(ar_results['S1->S2']['accuracy'])
            history['ar_s2_s3'].append(ar_results['S2->S3']['accuracy'])
            history['ar_s1_s3'].append(ar_results['S1->S3']['accuracy'])
            history['s1_s3_errors'].append(ar_results['S1->S3']['errors'])
            
            # æ‰“å°ç»“æœ
            print(f"\n{'='*60}")
            print(f"Iteration {iter_num}:")
            print(f"  Loss: train={avg_train_loss:.4f}, val={val_loss:.4f}")
            
            print(f"\n  Autoregressive Generation (Test Set):")
            for path_type in ['S1->S2', 'S2->S3', 'S1->S3']:
                res = ar_results[path_type]
                print(f"    {path_type}: {res['accuracy']:.2%} ({res['correct']}/{res['total']})")
                
                # æ‰“å°æˆåŠŸç¤ºä¾‹
                if res['examples']['success'] and iter_num <= 5000:  # å‰æœŸæ‰“å°ç¤ºä¾‹
                    ex = res['examples']['success'][0]
                    print(f"      âœ“ Example: {ex['source']}â†’{ex['target']}, generated: {ex['generated']}")
                
                # æ‰“å°é”™è¯¯åˆ†å¸ƒ
                if res['errors']:
                    error_str = ', '.join([f"{k}: {v}" for k, v in res['errors'].items()])
                    print(f"      Errors: {error_str}")
            
            # ç»„åˆèƒ½åŠ›è¯„ä¼°
            if iter_num >= 10000:
                s1_s2_acc = ar_results['S1->S2']['accuracy']
                s2_s3_acc = ar_results['S2->S3']['accuracy']
                s1_s3_acc = ar_results['S1->S3']['accuracy']
                
                if s1_s2_acc > 0.8 and s2_s3_acc > 0.8:
                    if s1_s3_acc > 0.8:
                        print("\n  âœ… Model demonstrates strong compositional ability!")
                    elif s1_s3_acc < 0.2:
                        print("\n  âš ï¸  Poor composition ability despite good basic performance!")
            
            # è®°å½•æ—¥å¿—
            logger.info(f"Iter {iter_num}: loss={avg_train_loss:.4f}, "
                       f"S1->S2={ar_results['S1->S2']['accuracy']:.2%}, "
                       f"S2->S3={ar_results['S2->S3']['accuracy']:.2%}, "
                       f"S1->S3={ar_results['S1->S3']['accuracy']:.2%}")
            
            running_loss = 0
            loss_count = 0
            model.train()
        
        # ä¿å­˜checkpoint
        if iter_num % args.checkpoint_interval == 0 and iter_num > 0:
            checkpoint = {
                'model': model.state_dict(),
                'optimizer': optimizer.state_dict(),
                'model_args': model_args,
                'iter_num': iter_num,
                'history': history,
                'config': vars(args)
            }
            checkpoint_path = os.path.join(out_dir, f'ckpt_{iter_num}.pt')
            torch.save(checkpoint, checkpoint_path)
            print(f"  Checkpoint saved to {checkpoint_path}")
        
        if iter_num == 0:
            continue
        
        # è®­ç»ƒæ­¥
        X, Y = get_batch('train')
        
        logits, loss = model(X, Y)
        
        optimizer.zero_grad(set_to_none=True)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        
        running_loss += loss.item()
        loss_count += 1
    
    # ä¿å­˜æœ€ç»ˆç»“æœ
    with open(os.path.join(out_dir, 'history.pkl'), 'wb') as f:
        pickle.dump(history, f)
    
    # ç»˜åˆ¶ç»“æœå›¾
    plot_results(history, out_dir)
    
    # æ‰“å°æœ€ç»ˆæ€»ç»“
    print_final_summary(history, logger)
    
    print(f"\nResults saved to: {out_dir}")

def plot_results(history, out_dir):
    """ç»˜åˆ¶è®­ç»ƒç»“æœ"""
    plt.figure(figsize=(15, 10))
    
    # 1. æŸå¤±æ›²çº¿
    plt.subplot(2, 2, 1)
    plt.plot(history['iter'], history['train_loss'], 'b-', label='Train')
    plt.plot(history['iter'], history['val_loss'], 'r-', label='Val')
    plt.xlabel('Iteration')
    plt.ylabel('Loss')
    plt.title('Training Loss')
    plt.legend()
    plt.grid(True)
    
    # 2. ARå‡†ç¡®ç‡
    plt.subplot(2, 2, 2)
    plt.plot(history['iter'], history['ar_s1_s2'], 'b-', label='S1->S2', marker='o', markersize=3)
    plt.plot(history['iter'], history['ar_s2_s3'], 'g-', label='S2->S3', marker='s', markersize=3)
    plt.plot(history['iter'], history['ar_s1_s3'], 'r-', label='S1->S3', marker='^', markersize=3, linewidth=2)
    plt.xlabel('Iteration')
    plt.ylabel('Accuracy')
    plt.title('Autoregressive Generation Accuracy')
    plt.legend()
    plt.grid(True)
    plt.ylim(0, 1.05)
    
    # 3. ç»„åˆèƒ½åŠ›å·®è·
    plt.subplot(2, 2, 3)
    if len(history['ar_s1_s2']) > 0:
        basic_avg = [(h1 + h2) / 2 for h1, h2 in zip(history['ar_s1_s2'], history['ar_s2_s3'])]
        composition_gap = [b - c for b, c in zip(basic_avg, history['ar_s1_s3'])]
        plt.plot(history['iter'], composition_gap, 'purple', linewidth=2)
        plt.axhline(y=0, color='k', linestyle='--', alpha=0.5)
        plt.xlabel('Iteration')
        plt.ylabel('Gap')
        plt.title('Composition Gap (Basic Avg - S1->S3)')
        plt.grid(True)
    
    # 4. S1->S3å‡†ç¡®ç‡å•ç‹¬å±•ç¤º
    plt.subplot(2, 2, 4)
    plt.plot(history['iter'], history['ar_s1_s3'], 'r-', linewidth=2, marker='o', markersize=4)
    plt.axhline(y=1.0, color='g', linestyle='--', alpha=0.3, label='Perfect')
    plt.axhline(y=0.9, color='orange', linestyle='--', alpha=0.3, label='90%')
    plt.axhline(y=0.8, color='red', linestyle='--', alpha=0.3, label='80%')
    plt.xlabel('Iteration')
    plt.ylabel('Accuracy')
    plt.title('S1->S3 Composition Performance')
    plt.legend()
    plt.grid(True)
    plt.ylim(0, 1.05)
    
    plt.tight_layout()
    plt.savefig(os.path.join(out_dir, 'training_results.png'), dpi=150)
    plt.close()

def print_final_summary(history, logger):
    """æ‰“å°æœ€ç»ˆæ€»ç»“"""
    print(f"\n{'='*60}")
    print("Training Complete!")
    
    if not history['ar_s1_s2']:
        print("No evaluation data available.")
        return
    
    print(f"\nFinal Results:")
    print(f"  S1->S2: {history['ar_s1_s2'][-1]:.2%}")
    print(f"  S2->S3: {history['ar_s2_s3'][-1]:.2%}")
    print(f"  S1->S3: {history['ar_s1_s3'][-1]:.2%} â† Composition Performance")
    
    # åˆ†æ
    basic_performance = (history['ar_s1_s2'][-1] + history['ar_s2_s3'][-1]) / 2
    composition_performance = history['ar_s1_s3'][-1]
    
    print(f"\nComposition Analysis:")
    print(f"  Basic Path Average: {basic_performance:.2%}")
    print(f"  Composition Performance: {composition_performance:.2%}")
    print(f"  Composition Gap: {abs(basic_performance - composition_performance):.2%}")
    
    if composition_performance > 0.8:
        print("\nâœ… Model demonstrates STRONG compositional generalization!")
        logger.info("RESULT: Strong compositional generalization observed")
    elif composition_performance > 0.5:
        print("\nğŸ”¶ Model shows moderate compositional ability.")
        logger.info("RESULT: Moderate compositional ability")
    else:
        print("\nâš ï¸  Model shows limited compositional generalization.")
        logger.info("RESULT: Limited compositional generalization")

if __name__ == "__main__":
    main()